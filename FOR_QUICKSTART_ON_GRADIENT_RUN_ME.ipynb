{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97823a0d-5fcf-4e91-93d6-40339c65ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell first to install dependencies\n",
    "!pip install scikit-image optuna imutils python-dotenv seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d2ba35-6278-4d6b-a81a-865a3057a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run hyperparameter search\n",
    "# Usage: hyperparameter_search.py [OPTIONS]\n",
    "#\n",
    "# Options:\n",
    "#   -m, --model [resnet18|inception_v3|vision_transformer]\n",
    "#                                  Model architechture.  [required]\n",
    "#   -e, --no_of_epochs INTEGER      Number of epochs in training loop.\n",
    "#   -t, --no_of_trials INTEGER      Number of hyperparamter search trials in\n",
    "#                                   training loop.\n",
    "#   -d, --dataset [plant|plant_golden|leaf|leaf_golden]\n",
    "#                                   Already available dataset to use to train\n",
    "#                                   the model. Give either -d or -csv, not both.\n",
    "#   -csv, --data-csv TEXT           Full file path to dataset CSV-file created\n",
    "#                                   during segmentation. Give either -d or -csv,\n",
    "#                                   not both.\n",
    "#   -b, --binary                    Train binary classifier instead of\n",
    "#                                   multiclass classifier.  [default: False]\n",
    "#   -aug, --augmentation            Use data-augmentation for the training.\n",
    "#                                   [default: True]\n",
    "#   -s, --save                      Save the trained model and add information\n",
    "#                                   to model dataframe.  [default: True]\n",
    "#   -v, --verbose                   Print verbose logs.  [default: False]\n",
    "#   --help                          Show this message and exit.\n",
    "\n",
    "%run -i 'hyperparameter_search.py' --model resnet18 --dataset leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652dc958-3a25-44aa-a575-116ad7dcc155",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run training with the model selected (whose hyperparameters are in hyperparams.yaml file)\n",
    "# Usage: train.py [OPTIONS]\n",
    "#\n",
    "# Options:\n",
    "#   -m, --model [resnet18|inception_v3|vision_transformer]\n",
    "#                                   Model architechture.  [required]\n",
    "#   -d, --dataset [plant|plant_golden|leaf|leaf_golden]\n",
    "#                                   Already available dataset to use to train\n",
    "#                                   the model. Give either -d or -csv, not both.\n",
    "#   -csv, --data-csv TEXT           Full file path to dataset CSV-file created\n",
    "#                                   during segmentation. Give either -d or -csv,\n",
    "#                                   not both.\n",
    "#   -b, --binary                    Train binary classifier instead of\n",
    "#                                   multiclass classifier.  [default: False]\n",
    "#   -p, --params-file TEXT          Full file path to hyperparameter-file used\n",
    "#                                   during the training. File must be a YAMl\n",
    "#                                   file and similarly structured than\n",
    "#                                   hyperparams.yaml.\n",
    "#   -aug, --augmentation            Use data-augmentation for the training.\n",
    "#                                   [default: True]\n",
    "#   -s, --save                      Save the trained model and add information\n",
    "#                                   to model dataframe.  [default: True]\n",
    "#   -v, --verbose                   Print verbose logs.  [default: False]\n",
    "#   --help                          Show this message and exit.\n",
    "\n",
    "%run -i 'train.py' --model resnet18 --dataset leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1f7b64-8c18-40ee-8cd8-5b49f48f2852",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run prediction with the most viable model\n",
    "# Usage: predict.py [OPTIONS]\n",
    "#\n",
    "# Options:\n",
    "#   -i, --input TEXT                Path to input image.  [required]\n",
    "#   -id, --identifier TEXT          Model id. You can print model info with\n",
    "#                                   help.py.\n",
    "#   -m, --model [resnet18|inception_v3|vision_transformer]\n",
    "#                                   Model architechture.\n",
    "#   -n, --num-classes INTEGER       Number of classes (2 in binary case, 4 in\n",
    "#                                   multi-class case).\n",
    "#   -d, --dataset TEXT              Name of the dataset model is trained on.\n",
    "#   -v, --verbose                   Print verbose logs.  [default: False]\n",
    "#   --help\n",
    "    \n",
    "%run -i 'predict.py' --model resnet18 --input \"./image_to_be_predicted.png\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
