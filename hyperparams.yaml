resnet18:
  OPTIMIZER: AdamW
  N_EPOCHS: 20
  BATCH_SIZE_TRAIN: 64
  BATCH_SIZE_TEST: 64
  LR: 6.034707533627368e-05
  WEIGHT_DECAY: 0.029969461595855246
  DAMPENING: N/A
  MOMENTUM: N/A
  EPS: 9.393025734871389e-05
  BETAS: (0.95, 0.999)
  LR_DECAY: N/A
  ALPHA: N/A
  NUM_HEADS: N/A
  DROPOUT: N/A
inception_v3:
  OPTIMIZER: AdamW
  N_EPOCHS: 20
  BATCH_SIZE_TRAIN: 64
  BATCH_SIZE_TEST: 64
  LR: 0.00037380936503458065
  WEIGHT_DECAY: 0.058507229838383946
  DAMPENING: N/A
  MOMENTUM: N/A
  EPS: 1.9187779962213316e-05
  BETAS: (0.9, 0.99)
  LR_DECAY: N/A
  ALPHA: N/A
  NUM_HEADS: N/A
  DROPOUT: N/A
vision_transformer:
  OPTIMIZER: SGD
  N_EPOCHS: 200
  BATCH_SIZE_TRAIN: 64
  BATCH_SIZE_TEST: 64
  LR: 0.01
  WEIGHT_DECAY: 0.01
  DAMPENING: 0
  MOMENTUM: 0.9
  EPS: 0.00000001
  BETAS: (0.9, 0.999)
  LR_DECAY: 0
  ALPHA: 0.99
  NUM_HEADS: 8
  DROPOUT: 0.0
bag_of_words:
  FEATURE_DETECTION: 'SIFT' # SIFT is better for both plant and leaf data for both binary and multiclass
  CLASSIFIER: 'XGBoost' # XGBoost is generally the best, but RandomForest seemed slightly better for multiclass classification on leaf data
  BINARY:
    SIFT:
      XGBoost: # accuracy ~0.91, f1 score ~0.91
        LR: 0.3
        GAMMA: 0
        MAX_DEPTH: 3
        MIN_CHILD_WEIGHT: 0
        K: 100
      RandomForest: # accuracy ~0.88, f1 score ~0.87
        N_ESTIMATORS: 300
        CRITERION: 'entropy'
        MAX_DEPTH: null
        MIN_SAMPLES_SPLIT: 4
        K: 100
      SVM: # accuracy ~0.88, f1 score ~0.87
        C: 1
        KERNEL: 'rbf'
        GAMMA: 0.001
        K: 500
    ORB: # accuracy ~0.81, f1 score ~0.8
      XGBoost:
        LR: 0.7
        GAMMA: 1
        MAX_DEPTH: 3
        MIN_CHILD_WEIGHT: 1
        K: 200
      RandomForest: # accuracy ~0.86, f1 score ~0.84
        N_ESTIMATORS: 100
        CRITERION: 'gini'
        MAX_DEPTH: null
        MIN_SAMPLES_SPLIT: 4
        K: 100
      SVM: # accuracy ~0.86, f1 score ~0.85
        C: 10
        KERNEL: 'rbf'
        GAMMA: 0.001
        K: 500
  MULTICLASS:
    SIFT:
      XGBoost: # accuracy ~0.65, f1 score ~0.62
        LR: 0.3
        GAMMA: 0
        MAX_DEPTH: null
        MIN_CHILD_WEIGHT: 1
        K: 200
      RandomForest: # accuracy ~0.65, f1 score ~0.6
        N_ESTIMATORS: 300
        CRITERION: 'gini'
        MAX_DEPTH: null
        MIN_SAMPLES_SPLIT: 2
        K: 100
      SVM: # accuracy ~0.63, f1 score ~0.59
        C: 1
        KERNEL: 'rbf'
        GAMMA: 'auto'
        K: 200
    ORB:
      XGBoost: # accuracy ~0.58, f1 score ~0.56
        LR: 0.3
        GAMMA: 1
        MAX_DEPTH: 3
        MIN_CHILD_WEIGHT: 1
        K: 200
      RandomForest: # accuracy ~0.59, f1 score ~0.52
        N_ESTIMATORS: 400
        CRITERION: 'gini'
        MAX_DEPTH: null
        MIN_SAMPLES_SPLIT: 2
        K: 100
      SVM: # accuracy ~0.57, f1 score ~0.56
        C: 10
        KERNEL: 'sigmoid'
        GAMMA: 0.001
        K: 200
