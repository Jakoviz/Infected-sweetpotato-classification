resnet18:
  HYPERPARAM_SEARCH_ID: a29yoyfu-resnet18-160522_22:52
  OPTIMIZER: SGD
  N_EPOCHS: 100
  BATCH_SIZE_TRAIN: 64
  BATCH_SIZE_TEST: 64
  LR: 0.01
  WEIGHT_DECAY: 0.01
  DAMPENING: 0
  MOMENTUM: 0.9
  EPS: 0.00000001
  BETAS: (0.9, 0.999)
  LR_DECAY: 0
  ALPHA: 0.99
  NUM_HEADS: 8
  DROPOUT: 0.2
inception_v3:
  HYPERPARAM_SEARCH_ID: X
  OPTIMIZER: SGD
  N_EPOCHS: 100
  BATCH_SIZE_TRAIN: 32
  BATCH_SIZE_TEST: 32
  LR: 0.01
  WEIGHT_DECAY: 0.01
  DAMPENING: 0
  MOMENTUM: 0.9
  EPS: 0.00000001
  BETAS: (0.9, 0.999)
  LR_DECAY: 0
  ALPHA: 0.99
  NUM_HEADS: 8
  DROPOUT: 0.2
vision_transformer:
  HYPERPARAM_SEARCH_ID: X
  OPTIMIZER: SGD
  N_EPOCHS: 200
  BATCH_SIZE_TRAIN: 64
  BATCH_SIZE_TEST: 64
  LR: 0.01
  WEIGHT_DECAY: 0.01
  DAMPENING: 0
  MOMENTUM: 0.9
  EPS: 0.00000001
  BETAS: (0.9, 0.999)
  LR_DECAY: 0
  ALPHA: 0.99
  NUM_HEADS: 8
  DROPOUT: 0.0
bag_of_words:
  FEATURE_DETECTION: 'SIFT' # SIFT is better for both plant and leaf data for both binary and multiclass
  CLASSIFIER: 'XGBoost' # XGBoost is generally the best, but RandomForest seemed slightly better for multiclass classification on leaf data
  BINARY:
    SIFT:
      XGBoost: # accuracy ~0.91, f1 score ~0.91
        LR: 0.3
        GAMMA: 0
        MAX_DEPTH: 3
        MIN_CHILD_WEIGHT: 0
        K: 100
      RandomForest: # accuracy ~0.88, f1 score ~0.87
        N_ESTIMATORS: 300
        CRITERION: 'entropy'
        MAX_DEPTH: null
        MIN_SAMPLES_SPLIT: 4
        K: 100
      SVM: # accuracy ~0.88, f1 score ~0.87
        C: 1
        KERNEL: 'rbf'
        GAMMA: 0.001
        K: 500
    ORB: # accuracy ~0.81, f1 score ~0.8
      XGBoost:
        LR: 0.7
        GAMMA: 1
        MAX_DEPTH: 3
        MIN_CHILD_WEIGHT: 1
        K: 200
      RandomForest: # accuracy ~0.86, f1 score ~0.84
        N_ESTIMATORS: 100
        CRITERION: 'gini'
        MAX_DEPTH: null
        MIN_SAMPLES_SPLIT: 4
        K: 100
      SVM: # accuracy ~0.86, f1 score ~0.85
        C: 10
        KERNEL: 'rbf'
        GAMMA: 0.001
        K: 500
  MULTICLASS:
    SIFT:
      XGBoost: # accuracy ~0.65, f1 score ~0.62
        LR: 0.3
        GAMMA: 0
        MAX_DEPTH: null
        MIN_CHILD_WEIGHT: 1
        K: 200
      RandomForest: # accuracy ~0.65, f1 score ~0.6
        N_ESTIMATORS: 300
        CRITERION: 'gini'
        MAX_DEPTH: null
        MIN_SAMPLES_SPLIT: 2
        K: 100
      SVM: # accuracy ~0.63, f1 score ~0.59
        C: 1
        KERNEL: 'rbf'
        GAMMA: 'auto'
        K: 200
    ORB:
      XGBoost: # accuracy ~0.58, f1 score ~0.56
        LR: 0.3
        GAMMA: 1
        MAX_DEPTH: 3
        MIN_CHILD_WEIGHT: 1
        K: 200
      RandomForest: # accuracy ~0.59, f1 score ~0.52
        N_ESTIMATORS: 400
        CRITERION: 'gini'
        MAX_DEPTH: null
        MIN_SAMPLES_SPLIT: 2
        K: 100
      SVM: # accuracy ~0.57, f1 score ~0.56
        C: 10
        KERNEL: 'sigmoid'
        GAMMA: 0.001
        K: 200
